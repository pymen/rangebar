{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the impact of filler bars or no filler bars on strategy profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pyperclip as clip\n",
    "import ta\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../tmp-data/ss_range_bars.final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/btcusdt-1year-1m-merged.csv', usecols=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df['date'] = pd.to_datetime(df['timestamp']).dt.date \n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df.rename(columns={'close': 'Close', 'open': 'Open', 'high': 'High', 'low': 'Low'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adr(df: pd.DataFrame) -> float:\n",
    "    daily_high_low = df.groupby(  # type: ignore\n",
    "                'date')[['High', 'Low']].agg(['max', 'min']) # type: ignore\n",
    "    high_max: pd.Series = daily_high_low[('High', 'max')]\n",
    "    low_min: pd.Series = daily_high_low[('Low', 'min')]\n",
    "    # convert the Series to numeric values\n",
    "    high_max = pd.to_numeric(high_max, errors='coerce')\n",
    "    low_min = pd.to_numeric(low_min, errors='coerce')\n",
    "    adr = high_max - low_min # type: ignore\n",
    "    daily_high_low['adr'] = adr\n",
    "    average_adr = np.mean(daily_high_low['adr']).item()  # type: ignore\n",
    "    return average_adr\n",
    "\n",
    "def relative_adr_range_size(df_in: pd.DataFrame, resample_arg: str = 'W'):\n",
    "    # resample the dataframe into monthly periods\n",
    "    groups = df_in.resample(resample_arg)\n",
    "    df_out = pd.DataFrame()\n",
    "    for _, group in groups:\n",
    "        week_day_seg = group.copy()\n",
    "        average_adr = adr(week_day_seg)\n",
    "        week_day_seg['average_adr'] = average_adr\n",
    "        df_out = pd.concat([df_out, week_day_seg])\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv(df: pd.DataFrame, window=14) -> pd.Series:\n",
    "    result = df['volume'].rolling(window=window).mean()\n",
    "    result.fillna(0, inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = df.copy()\n",
    "df2 = relative_adr_range_size(cp)\n",
    "df2['adv'] = adv(cp)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_range_bar_df(df: pd.DataFrame):\n",
    "    range_bars = []\n",
    "    current_bar = {'adv': df.iloc[0]['adv'], 'volume': df.iloc[0]['volume'], 'average_adr': df.iloc[0]['average_adr'], 'timestamp': df.index.to_series(\n",
    "    )[0], 'Open': df.iloc[0]['Open'], 'High': df.iloc[0]['High'], 'Low': df.iloc[0]['Low'], 'Close': df.iloc[0]['Close']}\n",
    "    current_high = current_bar['High']\n",
    "    current_low = current_bar['Low']\n",
    "    filler_bars = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        high = row['High']\n",
    "        low = row['Low']\n",
    "        range_size = row['average_adr'] * 0.1\n",
    "\n",
    "        if high - current_low >= range_size:\n",
    "            current_bar['Close'] = current_low + range_size\n",
    "            range_bars.append(current_bar)\n",
    "\n",
    "            num_bars = int((high - current_low - range_size) // range_size)\n",
    "            for i in range(num_bars):\n",
    "                current_bar = {'timestamp': pd.Timestamp(index) + pd.Timedelta(seconds=(i + 1)), 'adv': row['adv'], 'volume': row['volume'], 'average_adr': row['average_adr'], 'Open': current_low + range_size * (\n",
    "                    i), 'High': current_low + range_size * (i + 1), 'Low': current_low + range_size * (i), 'Close': current_low + range_size * (i + 1)}\n",
    "                # print(f'adjusted timestamp: {current_bar[\"timestamp\"]}')\n",
    "                filler_bars += 1\n",
    "                range_bars.append(current_bar)\n",
    "\n",
    "            current_bar = {'volume': row['volume'] * num_bars, 'average_adr': row['average_adr'], 'adv': row['adv'], 'timestamp': index,\n",
    "                           'Open': current_low + range_size * num_bars, 'High': high, 'Low': current_low + range_size * num_bars, 'Close': row['Close']}\n",
    "            current_high = high\n",
    "            current_low = current_bar['Low']\n",
    "\n",
    "        elif current_high - low >= range_size:\n",
    "            current_bar['Close'] = current_high - range_size\n",
    "            range_bars.append(current_bar)\n",
    "\n",
    "            num_bars = int((current_high - low - range_size) // range_size)\n",
    "            for i in range(num_bars):\n",
    "                current_bar = {'timestamp': pd.Timestamp(index) + pd.Timedelta(seconds=(i + 1)), 'adv': row['adv'], 'volume': row['volume'], 'average_adr': row['average_adr'], 'Open': current_high - range_size * (\n",
    "                    i + 1), 'High': current_high - range_size * (i), 'Low': current_high - range_size * (i + 1), 'Close': current_high - range_size * (i + 1)}\n",
    "                # print(f'adjusted timestamp: {current_bar[\"timestamp\"]}')\n",
    "                filler_bars += 1\n",
    "                range_bars.append(current_bar)\n",
    "\n",
    "            current_bar = {'volume': row['volume'] * (num_bars + 1), 'average_adr': row['average_adr'], 'adv': row['adv'], 'timestamp': index,\n",
    "                           'Open': current_high - range_size * (num_bars + 1), 'High': current_high - range_size * num_bars, 'Low': low, 'Close': row['Close']}\n",
    "            current_high = current_bar['High']\n",
    "            current_low = low\n",
    "        else:\n",
    "            current_high = max(current_high, high)\n",
    "            current_low = min(current_low, low)\n",
    "            current_bar['timestamp'] = index\n",
    "            current_bar['High'] = current_high\n",
    "            current_bar['Low'] = current_low\n",
    "            current_bar['Close'] = row['Close']\n",
    "            current_bar['average_adr'] = row['average_adr']\n",
    "            current_bar['volume'] = row['volume']\n",
    "            current_bar['adv'] = row['adv']\n",
    "\n",
    "    return pd.DataFrame(range_bars), filler_bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df, filler_bars = create_range_bar_df(df2.copy())\n",
    "print(f'filler bars: {filler_bars}')\n",
    "# Count the number of rows containing NaN values\n",
    "num_nan_rows = df.isna().any(axis=1).sum()\n",
    "print(f'num_nan_rows: {num_nan_rows}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df['timestamp'] = pd.to_datetime(rb_df['timestamp'])\n",
    "rb_df.set_index('timestamp', inplace=True)\n",
    "rb_df.sort_index(inplace=True)\n",
    "rb_df_copy = rb_df.copy()\n",
    "rb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MACD with custom parameters\n",
    "macd = ta.trend.MACD(rb_df['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "# add MACD values to the dataframe as new columns\n",
    "rb_df['macd'] = macd.macd()\n",
    "rb_df['macd_signal'] = macd.macd_signal()\n",
    "rb_df['macd_histogram'] = macd.macd_diff()\n",
    "rb_df.dropna(inplace=True)\n",
    "rb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = ta.volatility.BollingerBands(rb_df['Close'], window=12, window_dev=2)\n",
    "\n",
    "# add upper and lower Bollinger Bands to the dataframe as new columns\n",
    "rb_df['bb_upper'] = bb.bollinger_hband()\n",
    "rb_df['bb_lower'] = bb.bollinger_lband()\n",
    "rb_df['bb_distance'] = bb.bollinger_hband() - bb.bollinger_lband()\n",
    "rb_df.dropna(inplace=True)\n",
    "rb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi = ta.momentum.RSIIndicator(rb_df['Close'], window=7).rsi()\n",
    "rb_df['rsi'] = rsi\n",
    "rb_df.dropna(inplace=True)\n",
    "rb_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df['signal'] = 0\n",
    "rb_df['false_signal'] = -1\n",
    "rb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangeBarStrategy:\n",
    "    \n",
    "    long_indexes = []\n",
    "    short_indexes = []\n",
    "    anti_squeeze_distance = 10\n",
    "  \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.updated_df = pd.DataFrame()\n",
    "\n",
    "    def bb_upper_near(self, index, row):\n",
    "        try:\n",
    "            upper_series = self.df.iloc[:index+1]['bb_upper']\n",
    "            if len(upper_series) < 2:\n",
    "                return False\n",
    "            # print(f'upper_series:\\n{str(upper_series)}')\n",
    "            close = row['Close']\n",
    "            since = self.iterations_back_till_condition(upper_series, lambda x: x >= close)\n",
    "            # print(f'bb_upper_near(upper_series >= close): index: {index}, close: {close}, since: {since}')\n",
    "            return since < 2\n",
    "        except Exception as e:\n",
    "            print(f'bb_upper_near: exception: {e.__cause__}')\n",
    "            raise e\n",
    "        \n",
    "\n",
    "    def bb_lower_near(self, index, row):\n",
    "       try:\n",
    "         lower_series = self.df.iloc[:index+1]['bb_lower']\n",
    "         if len(lower_series) < 2:\n",
    "                return False\n",
    "        #  print(f'lower_series:\\n{str(lower_series)}')\n",
    "         close = row['Close']\n",
    "         since = self.iterations_back_till_condition(lower_series, lambda x: x <= close)\n",
    "        #  print(f'bb_lower_near(lower_series <= close): index: {index}, close: {close}, since: {since}')\n",
    "         return since < 2\n",
    "       except Exception as e:\n",
    "            print(f'bb_lower_near: exception: {e.__cause__}')\n",
    "            raise e\n",
    "       \n",
    "    def iterations_back_till_condition(self, series, condition):\n",
    "        count = 0\n",
    "        for value in series[::-1]:\n",
    "            if condition(value):\n",
    "                break\n",
    "            count += 1\n",
    "        return count\n",
    "       \n",
    "    def bb_upper_pointing_up(self, index):\n",
    "        from scipy.stats import linregress\n",
    "        bb_seg = self.df.iloc[index-3:index+1]['bb_upper']\n",
    "        # print(f'bb_seg: {len(bb_seg)}')\n",
    "        if len(bb_seg) > 0:\n",
    "            seg_len = len(bb_seg)\n",
    "            try:\n",
    "                slope, _, _, _, _ = linregress(range(seg_len), bb_seg)\n",
    "                # print(f'bb_upper_pointing_up: seg_len: {seg_len}, slope: {slope}')\n",
    "                return slope > 0\n",
    "            except Exception as e:\n",
    "                print(f'bb_upper_pointing_up: exception: {str(e)}')\n",
    "        return False\n",
    "\n",
    "    def bb_lower_pointing_down(self, index):\n",
    "        from scipy.stats import linregress\n",
    "        bb_seg = self.df.iloc[index-3:index+1]['bb_lower']\n",
    "        # print(f'bb_seg: {len(bb_seg)}')\n",
    "        if len(bb_seg) > 0:\n",
    "            seg_len = len(bb_seg)\n",
    "            try:\n",
    "                slope, _, _, _, _ = linregress(range(seg_len), bb_seg)\n",
    "                # print(f'bb_lower_pointing_down: seg_len: {seg_len}, slope: {slope}')\n",
    "                return slope < 0\n",
    "            except Exception as e:\n",
    "                print(f'bb_lower_pointing_down: exception: {str(e)}')  \n",
    "           \n",
    "        return False\n",
    "    \n",
    "    def scan(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            try:\n",
    "                numeric_index = self.df.index.get_loc(index)\n",
    "                # print(f'numeric_index: {numeric_index}')\n",
    "                updated_row = self.next(row, numeric_index, index)\n",
    "                self.df.loc[index] = updated_row\n",
    "                if numeric_index % 10000 == 0:\n",
    "                    print(f'progress index: {index}')\n",
    "            except Exception as e:\n",
    "                print(f'next: exception: {str(e)}')\n",
    "\n",
    "    def next(self, row, numeric_index, index):\n",
    "        is_long_rsi = row['rsi'] > 70\n",
    "        is_long_macd = row['macd'] > row['macd_signal'] > 0\n",
    "        is_bb_upper_near = self.bb_upper_near(numeric_index, row)\n",
    "        is_bb_upper_pointing_up = self.bb_upper_pointing_up(numeric_index)\n",
    "\n",
    "        is_short_rsi = row['rsi'] < 30\n",
    "        is_short_macd = row['macd'] < row['macd_signal'] < 0\n",
    "        is_bb_lower_near = self.bb_lower_near(numeric_index, row)\n",
    "        is_bb_lower_pointing_down = self.bb_lower_pointing_down(numeric_index)\n",
    "\n",
    "        is_volume_above_adv_limit = row['volume'] > 0 and row['volume'] > row['adv']\n",
    "        is_bb_dist_above = row['bb_distance'] > self.anti_squeeze_distance\n",
    "\n",
    "        if is_long_rsi and is_long_macd and is_bb_upper_near and is_bb_upper_pointing_up and is_bb_dist_above:\n",
    "            self.long_indexes.append(index)\n",
    "            row['signal'] = 1\n",
    "        elif is_short_rsi and is_short_macd and is_bb_lower_near and is_bb_lower_pointing_down and is_bb_dist_above and is_volume_above_adv_limit:\n",
    "            row['signal'] = -1\n",
    "            self.short_indexes.append(index)\n",
    "        else:\n",
    "            row['signal'] = 0\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows containing NaN values\n",
    "num_nan_rows = rb_df.isna().any(axis=1).sum()\n",
    "print(f'num_nan_rows: {num_nan_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = rb_df\n",
    "strategy = RangeBarStrategy(df_sample)\n",
    "strategy.scan()\n",
    "print(f'long_indexes: {len(strategy.long_indexes)}')\n",
    "print(f'short_indexes: {len(strategy.short_indexes)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With is_not_eq_last_close\n",
    "### 7 day average adr\n",
    "* long_indexes: 1872\n",
    "* short_indexes: 2083"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using 3 on near\n",
    "false_signals: 1697, true_signals: 8707, diff: 7010\n",
    "false_signals: 1841, true_signals: 9182, diff: 7341\n",
    "### using 2 on near\n",
    "false_signals: 1549, true_signals: 7952, diff: 6403\n",
    "false_signals: 1664, true_signals: 8266, diff: 6602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_len_before = len(df_sample)\n",
    "df_sample.dropna(inplace=True)\n",
    "na_len_after = len(df_sample)\n",
    "print(f'na_len_before: {na_len_before}, na_len_after: {na_len_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6206a5d9777dc4941d1ef736d0f3211132aba6ec6b27c0cc45f807d6cb74e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
