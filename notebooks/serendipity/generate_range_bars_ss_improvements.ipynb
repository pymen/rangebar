{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve SS Performance - eliminate negative profit months"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Problems From Visual Observations\n",
    "\n",
    "* on winner and loosers there are buys and sells at levels of resistance that would loose\n",
    "* there are multiple buys and sells on a flat line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to try\n",
    "\n",
    "1. if the next bars close is = to the last don't buy/sell (unsure this may reduce profit factor, the duplications are useful but maybe less so on the flat line) -- epic fail complete negative returns\n",
    "2. near needs to be one bar away -- it already is < 2 is 1 bar away\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. there should be a buy if closes outside the bottom bb and bb pointing down\n",
    "4. there should be a sell if closes outside the to bb and bb pointing up\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. reduce the average adr from 7 days to 3 days -- epic fail, complete negative returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pyperclip as clip\n",
    "import ta\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128800 rows at 1m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "102909 rows at 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../tmp-data/ss_strategy_1min_7d_avg_adr_range_bars.withoutbug.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = ['../data/BTCUSDT_1m_3m_back_from_2023-03-14.csv', '../data/BTCUSDT_1m_3m_back_from_2022-11-15.csv', '../data/BTCUSDT_1m_3m_back_from_2022-07-19.csv']\n",
    "df = pd.DataFrame()\n",
    "for csv_path in csv_paths:\n",
    "    df = pd.concat([df, pd.read_csv(csv_path, usecols=['timestamp', 'open', 'high', 'low', 'close', 'volume'])])\n",
    "\n",
    "df['date'] = pd.to_datetime(df['timestamp']).dt.date \n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "# df = df.resample('5T').agg({\n",
    "#     'date': 'first',\n",
    "#     'open': 'first',\n",
    "#     'high': 'max',\n",
    "#     'low': 'min',\n",
    "#     'close': 'last'\n",
    "# })\n",
    "df.rename(columns={'close': 'Close', 'open': 'Open', 'high': 'High', 'low': 'Low'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adr(df: pd.DataFrame) -> float:\n",
    "    daily_high_low = df.groupby('date')['High', 'Low'].agg(['max', 'min'])\n",
    "    daily_high_low['adr'] = daily_high_low[('High', 'max')] - daily_high_low[('Low', 'min')]\n",
    "    return np.mean(daily_high_low['adr'])\n",
    "\n",
    "def relative_adr_range_size(df_in: pd.DataFrame, resample_arg: str = 'W') -> str:\n",
    "    # resample the dataframe into monthly periods\n",
    "    groups = df_in.resample(resample_arg)\n",
    "    df_out = pd.DataFrame()\n",
    "    for _, group in groups:\n",
    "        week_day_seg = group.copy()\n",
    "        average_adr = adr(week_day_seg)\n",
    "        week_day_seg['average_adr'] = average_adr\n",
    "        df_out = pd.concat([df_out, week_day_seg])\n",
    "    return df_out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = relative_adr_range_size(df.copy())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_range_bar_df(df: pd.DataFrame):\n",
    "        range_bars = []\n",
    "        current_bar = {'volume': df.iloc[0]['volume'], 'average_adr': df.iloc[0]['average_adr'],'timestamp': df.index.to_series()[0], 'Open': df.iloc[0]['Open'], 'High': df.iloc[0]['High'], 'Low': df.iloc[0]['Low'], 'Close': df.iloc[0]['Close']}\n",
    "        current_high = current_bar['High']\n",
    "        current_low = current_bar['Low']\n",
    "        filler_bars = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            high = row['High']\n",
    "            low = row['Low']\n",
    "            range_size = row['average_adr'] * 0.1\n",
    "\n",
    "            if high - current_low >= range_size:\n",
    "                current_bar['Close'] = current_low + range_size\n",
    "                range_bars.append(current_bar)\n",
    "\n",
    "                num_bars = int((high - current_low - range_size) // range_size)\n",
    "                for i in range(num_bars):\n",
    "                    current_bar = {'timestamp': pd.Timestamp(index) + pd.Timedelta(seconds=(i + 1)), 'volume': row['volume'], 'average_adr': row['average_adr'], 'Open': current_low + range_size * (i), 'High': current_low + range_size * (i + 1), 'Low': current_low + range_size * (i), 'Close': current_low + range_size * (i + 1)}\n",
    "                    # print(f'adjusted timestamp: {current_bar[\"timestamp\"]}')\n",
    "                    filler_bars += 1\n",
    "                    range_bars.append(current_bar)\n",
    "\n",
    "                current_bar = {'volume': row['volume'] * num_bars, 'average_adr': row['average_adr'],'timestamp': index, 'Open': current_low + range_size * num_bars, 'High': high, 'Low': current_low + range_size * num_bars, 'Close': row['Close']}\n",
    "                current_high = high\n",
    "                current_low = current_bar['Low']\n",
    "\n",
    "            elif current_high - low >= range_size:\n",
    "                current_bar['Close'] = current_high - range_size\n",
    "                range_bars.append(current_bar)\n",
    "\n",
    "                num_bars = int((current_high - low - range_size) // range_size)\n",
    "                for i in range(num_bars):\n",
    "                    current_bar = {'timestamp': pd.Timestamp(index) + pd.Timedelta(seconds=(i + 1)), 'volume': row['volume'], 'average_adr': row['average_adr'], 'Open': current_high - range_size * (i + 1), 'High': current_high - range_size * (i), 'Low': current_high - range_size * (i + 1), 'Close': current_high - range_size * (i + 1)}\n",
    "                    # print(f'adjusted timestamp: {current_bar[\"timestamp\"]}')\n",
    "                    filler_bars += 1\n",
    "                    range_bars.append(current_bar)\n",
    "\n",
    "                current_bar = {'volume': row['volume'] * (num_bars + 1), 'average_adr': row['average_adr'],'timestamp': index, 'Open': current_high - range_size * (num_bars + 1), 'High': current_high - range_size * num_bars, 'Low': low, 'Close': row['Close']}\n",
    "                current_high = current_bar['High']\n",
    "                current_low = low\n",
    "            else:\n",
    "                current_high = max(current_high, high)\n",
    "                current_low = min(current_low, low)\n",
    "                current_bar['timestamp'] = index\n",
    "                current_bar['High'] = current_high\n",
    "                current_bar['Low'] = current_low\n",
    "                current_bar['Close'] = row['Close']\n",
    "                current_bar['average_adr'] = row['average_adr']\n",
    "                current_bar['volume'] = row['volume']\n",
    "\n",
    "        return pd.DataFrame(range_bars), filler_bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df, filler_bars = create_range_bar_df(df2.copy())\n",
    "print(f'filler bars: {filler_bars}')\n",
    "# Count the number of rows containing NaN values\n",
    "num_nan_rows = df.isna().any(axis=1).sum()\n",
    "print(f'num_nan_rows: {num_nan_rows}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df['timestamp'] = pd.to_datetime(rb_df['timestamp'])\n",
    "rb_df.set_index('timestamp', inplace=True)\n",
    "rb_df.sort_index(inplace=True)\n",
    "rb_df_copy = rb_df.copy()\n",
    "rb_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add macd, we select 26 for the slow moving average, 12 for the fast moving average and 9 for the signal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MACD with custom parameters\n",
    "macd = ta.trend.MACD(rb_df['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "# add MACD values to the dataframe as new columns\n",
    "rb_df['macd'] = macd.macd()\n",
    "rb_df['macd_signal'] = macd.macd_signal()\n",
    "rb_df['macd_histogram'] = macd.macd_diff()\n",
    "rb_df.dropna(inplace=True)\n",
    "rb_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add bb we select 12 for the moving average and 2 for the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = ta.volatility.BollingerBands(rb_df['Close'], window=12, window_dev=2)\n",
    "\n",
    "# add upper and lower Bollinger Bands to the dataframe as new columns\n",
    "rb_df['bb_upper'] = bb.bollinger_hband()\n",
    "rb_df['bb_lower'] = bb.bollinger_lband()\n",
    "rb_df['bb_distance'] = bb.bollinger_hband() - bb.bollinger_lband()\n",
    "rb_df.dropna(inplace=True)\n",
    "rb_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add rsi we use a value of 7 for the RSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate True Range (TR)\n",
    "def true_range(high, low, close):\n",
    "    tr1 = abs(high - low)\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    return pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "\n",
    "# Calculate the ATR using a rolling window of 14 periods\n",
    "atr_window = 14\n",
    "rb_df['_tr'] = true_range(rb_df['High'], rb_df['Low'], rb_df['Close'])\n",
    "rb_df['atr'] = rb_df['_tr'].rolling(window=atr_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi = ta.momentum.RSIIndicator(rb_df['Close'], window=7).rsi()\n",
    "rb_df['rsi'] = rsi\n",
    "rb_df.dropna(inplace=True)\n",
    "rb_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df['signal'] = 0\n",
    "rb_df['false_signal'] = -1\n",
    "rb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangeBarStrategy:\n",
    "    \n",
    "    long_indexes = []\n",
    "    short_indexes = []\n",
    "    anti_squeeze_distance = 10\n",
    "  \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.updated_df = pd.DataFrame()\n",
    "\n",
    "    def bb_upper_near(self, index, row):\n",
    "        try:\n",
    "            upper_series = self.df.iloc[:index+1]['bb_upper']\n",
    "            if len(upper_series) < 2:\n",
    "                return False\n",
    "            # print(f'upper_series:\\n{str(upper_series)}')\n",
    "            close = row['Close']\n",
    "            since = self.iterations_back_till_condition(upper_series, lambda x: x >= close)\n",
    "            # print(f'bb_upper_near(upper_series >= close): index: {index}, close: {close}, since: {since}')\n",
    "            return since < 2\n",
    "        except Exception as e:\n",
    "            print(f'bb_upper_near: exception: {e.__cause__}')\n",
    "            raise e\n",
    "        \n",
    "\n",
    "    def bb_lower_near(self, index, row):\n",
    "       try:\n",
    "         lower_series = self.df.iloc[:index+1]['bb_lower']\n",
    "         if len(lower_series) < 2:\n",
    "                return False\n",
    "        #  print(f'lower_series:\\n{str(lower_series)}')\n",
    "         close = row['Close']\n",
    "         since = self.iterations_back_till_condition(lower_series, lambda x: x <= close)\n",
    "        #  print(f'bb_lower_near(lower_series <= close): index: {index}, close: {close}, since: {since}')\n",
    "         return since < 2\n",
    "       except Exception as e:\n",
    "            print(f'bb_lower_near: exception: {e.__cause__}')\n",
    "            raise e\n",
    "       \n",
    "    def iterations_back_till_condition(self, series, condition):\n",
    "        count = 0\n",
    "        for value in series[::-1]:\n",
    "            if condition(value):\n",
    "                break\n",
    "            count += 1\n",
    "        return count\n",
    "       \n",
    "    def bb_upper_pointing_up(self, index):\n",
    "        from scipy.stats import linregress\n",
    "        bb_seg = self.df.iloc[index-3:index+1]['bb_upper']\n",
    "        # print(f'bb_seg: {len(bb_seg)}')\n",
    "        if len(bb_seg) > 0:\n",
    "            seg_len = len(bb_seg)\n",
    "            try:\n",
    "                slope, _, _, _, _ = linregress(range(seg_len), bb_seg)\n",
    "                # print(f'bb_upper_pointing_up: seg_len: {seg_len}, slope: {slope}')\n",
    "                return slope > 0\n",
    "            except Exception as e:\n",
    "                print(f'bb_upper_pointing_up: exception: {str(e)}')\n",
    "        return False\n",
    "\n",
    "    def bb_lower_pointing_down(self, index):\n",
    "        from scipy.stats import linregress\n",
    "        bb_seg = self.df.iloc[index-3:index+1]['bb_lower']\n",
    "        # print(f'bb_seg: {len(bb_seg)}')\n",
    "        if len(bb_seg) > 0:\n",
    "            seg_len = len(bb_seg)\n",
    "            try:\n",
    "                slope, _, _, _, _ = linregress(range(seg_len), bb_seg)\n",
    "                # print(f'bb_lower_pointing_down: seg_len: {seg_len}, slope: {slope}')\n",
    "                return slope < 0\n",
    "            except Exception as e:\n",
    "                print(f'bb_lower_pointing_down: exception: {str(e)}')  \n",
    "           \n",
    "        return False\n",
    "    \n",
    "    def scan(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            try:\n",
    "                numeric_index = self.df.index.get_loc(index)\n",
    "                # print(f'numeric_index: {numeric_index}')\n",
    "                updated_row = self.next(row, numeric_index, index)\n",
    "                self.df.loc[index] = updated_row\n",
    "            except Exception as e:\n",
    "                print(f'next: exception: {str(e)}')\n",
    "\n",
    "    def next(self, row, numeric_index, index):\n",
    "        is_long_rsi = row['rsi'] > 70\n",
    "        is_long_macd = row['macd'] > row['macd_signal'] > 0\n",
    "        is_bb_upper_near = self.bb_upper_near(numeric_index, row)\n",
    "        is_bb_upper_pointing_up = self.bb_upper_pointing_up(numeric_index)\n",
    "\n",
    "        is_short_rsi = row['rsi'] < 30\n",
    "        is_short_macd = row['macd'] < row['macd_signal'] < 0\n",
    "        is_bb_lower_near = self.bb_lower_near(numeric_index, row)\n",
    "        is_bb_lower_pointing_down = self.bb_lower_pointing_down(numeric_index)\n",
    "\n",
    "        # is_not_eq_last_close = row['Close'] != self.df.iloc[numeric_index-1]['Close']\n",
    "        is_bb_dist_above = row['bb_distance'] > self.anti_squeeze_distance\n",
    "\n",
    "        if is_long_rsi and is_long_macd and is_bb_upper_near and is_bb_upper_pointing_up and is_bb_dist_above:\n",
    "            self.long_indexes.append(index)\n",
    "            row['signal'] = 1\n",
    "        elif is_short_rsi and is_short_macd and is_bb_lower_near and is_bb_lower_pointing_down and is_bb_dist_above:\n",
    "            row['signal'] = -1\n",
    "            self.short_indexes.append(index)\n",
    "        else:\n",
    "            row['signal'] = 0\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows containing NaN values\n",
    "num_nan_rows = rb_df.isna().any(axis=1).sum()\n",
    "print(f'num_nan_rows: {num_nan_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = rb_df\n",
    "strategy = RangeBarStrategy(df_sample)\n",
    "strategy.scan()\n",
    "print(f'long_indexes: {len(strategy.long_indexes)}')\n",
    "print(f'short_indexes: {len(strategy.short_indexes)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without bb distance condition\n",
    "* long_indexes: 3997\n",
    "* short_indexes: 5060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows containing NaN values\n",
    "num_nan_rows = df_sample.isna().any(axis=1).sum()\n",
    "print(f'num_nan_rows: {num_nan_rows}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With is_not_eq_last_close\n",
    "### 3 day average adr\n",
    "* long_indexes: 1360\n",
    "* short_indexes: 1600\n",
    "### 7 day average adr\n",
    "* long_indexes: 1872\n",
    "* short_indexes: 2083"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using 3 on near\n",
    "false_signals: 1697, true_signals: 8707, diff: 7010\n",
    "false_signals: 1841, true_signals: 9182, diff: 7341\n",
    "### using 2 on near\n",
    "false_signals: 1549, true_signals: 7952, diff: 6403\n",
    "false_signals: 1664, true_signals: 8266, diff: 6602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_false_signals(df_sample: pd.DataFrame, indexes: list, expect_long: bool):\n",
    "    from scipy.stats import linregress\n",
    "    # count false signals\n",
    "    false_signals = 0\n",
    "    true_signals = 0\n",
    "    progress_count = 0\n",
    "    try:\n",
    "        for index in indexes:\n",
    "                idx = df_sample.index.get_loc(index)\n",
    "                seg = list(df_sample[idx:idx+3]['Close'])\n",
    "                # print(f'long seg: {str(seg)}')\n",
    "                slope, _, _, _, _ = linregress(range(len(seg)), seg)\n",
    "                if expect_long:\n",
    "                    if slope < 0:\n",
    "                        false_signals += 1\n",
    "                        df_sample.loc[index, 'false_signal'] = 1\n",
    "                    else:\n",
    "                        df_sample.loc[index, 'false_signal'] = 0\n",
    "                        true_signals += 1\n",
    "                else:\n",
    "                    if slope > 0:\n",
    "                        false_signals += 1\n",
    "                        df_sample.loc[index, 'false_signal'] = 1\n",
    "                    else:\n",
    "                        df_sample.loc[index, 'false_signal'] = 0\n",
    "                        true_signals += 1\n",
    "                progress_count += 1\n",
    "                if progress_count % 500 == 0:\n",
    "                    print(f'progress_count: {progress_count}')         \n",
    "    except Exception as e:\n",
    "        print(f'exception: {str(e)}')       \n",
    "    print(f'false_signals: {false_signals}, true_signals: {true_signals}, diff: {true_signals - false_signals}')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without bb distance condition\n",
    "* long_indexes: false_signals: 431, true_signals: 3566, diff: 3135\n",
    "* short_indexes: false_signals: 610, true_signals: 4450, diff: 3840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_false_signals(df_sample, strategy.long_indexes, True)\n",
    "mark_false_signals(df_sample, strategy.short_indexes, False)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_len_before = len(df_sample)\n",
    "df_sample.dropna(inplace=True)\n",
    "na_len_after = len(df_sample)\n",
    "print(f'na_len_before: {na_len_before}, na_len_after: {na_len_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6206a5d9777dc4941d1ef736d0f3211132aba6ec6b27c0cc45f807d6cb74e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
